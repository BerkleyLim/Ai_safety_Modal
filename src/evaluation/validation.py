# src/evaluation/validation.py
"""ëª¨ë¸ ë° í”„ë ˆì„ì›Œí¬ ì í•©ì„± ê²€ì¦ ëª¨ë“ˆ"""

import time
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional

from .metrics import get_best_metrics, YOLOMetrics


@dataclass
class ValidationResult:
    """ì í•©ì„± ê²€ì¦ ê²°ê³¼"""
    name: str
    passed: bool
    expected: str
    actual: str
    message: str = ""


@dataclass
class FrameworkValidation:
    """í”„ë ˆì„ì›Œí¬ ì í•©ì„± ê²€ì¦ ê²°ê³¼ ëª¨ìŒ"""
    results: list[ValidationResult] = field(default_factory=list)

    def add(self, result: ValidationResult):
        self.results.append(result)

    @property
    def all_passed(self) -> bool:
        return all(r.passed for r in self.results)

    @property
    def pass_count(self) -> int:
        return sum(1 for r in self.results if r.passed)

    @property
    def total_count(self) -> int:
        return len(self.results)

    def print_summary(self):
        print("\n" + "=" * 70)
        print("ğŸ” ëª¨ë¸ ë° í”„ë ˆì„ì›Œí¬ ì í•©ì„± ê²€ì¦ ê²°ê³¼")
        print("=" * 70)

        for r in self.results:
            status = "âœ… PASS" if r.passed else "âŒ FAIL"
            print(f"\n[{status}] {r.name}")
            print(f"   ê¸°ëŒ€ê°’: {r.expected}")
            print(f"   ì‹¤ì œê°’: {r.actual}")
            if r.message:
                print(f"   ë¹„ê³ : {r.message}")

        print("\n" + "-" * 70)
        print(f"ğŸ“Š ì¢…í•©: {self.pass_count}/{self.total_count} í•­ëª© í†µê³¼")
        if self.all_passed:
            print("âœ… ëª¨ë“  ì í•©ì„± ê²€ì¦ í†µê³¼ - í”„ë ˆì„ì›Œí¬ ì„¤ê³„ ê²€ì¦ ì™„ë£Œ")
        else:
            print("âš ï¸ ì¼ë¶€ í•­ëª© ë¯¸í†µê³¼ - ì¶”ê°€ ê²€í†  í•„ìš”")
        print("=" * 70)


def validate_yolo_model(model_path: str) -> ValidationResult:
    """YOLO ëª¨ë¸ íŒŒì¼ ê²€ì¦"""
    path = Path(model_path)
    exists = path.exists()
    size_mb = path.stat().st_size / (1024 * 1024) if exists else 0

    return ValidationResult(
        name="YOLO ëª¨ë¸ íŒŒì¼ ì¡´ì¬",
        passed=exists and size_mb > 1,
        expected="best.pt íŒŒì¼ ì¡´ì¬ (>1MB)",
        actual=f"{'ì¡´ì¬' if exists else 'ì—†ìŒ'} ({size_mb:.2f}MB)" if exists else "íŒŒì¼ ì—†ìŒ",
        message="í•™ìŠµëœ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ê°€ëŠ¥" if exists else ""
    )


def validate_yolo_performance(results_csv: str, min_map50: float = 0.5) -> ValidationResult:
    """YOLO ëª¨ë¸ ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦"""
    best = get_best_metrics(results_csv)

    if best is None:
        return ValidationResult(
            name="YOLO ëª¨ë¸ ì„±ëŠ¥ (mAP50)",
            passed=False,
            expected=f"mAP50 >= {min_map50}",
            actual="ê²°ê³¼ íŒŒì¼ ì—†ìŒ",
        )

    return ValidationResult(
        name="YOLO ëª¨ë¸ ì„±ëŠ¥ (mAP50)",
        passed=best.mAP50 >= min_map50,
        expected=f"mAP50 >= {min_map50}",
        actual=f"mAP50 = {best.mAP50:.4f} (Epoch {best.epoch})",
        message="ê°ì²´ íƒì§€ ì •í™•ë„ ê¸°ì¤€ ì¶©ì¡±" if best.mAP50 >= min_map50 else "ì¶”ê°€ í•™ìŠµ í•„ìš”"
    )


def validate_anomaly_detection() -> ValidationResult:
    """ì´ìƒ íƒì§€ ë¡œì§ ê²€ì¦ (ANOMALY_CLASSES ê¸°ë°˜)"""
    try:
        from monitoring import ANOMALY_CLASSES
        ua_count = sum(1 for c in ANOMALY_CLASSES if c.startswith(("forklift", "stacking", "person", "worker", "cargo", "flammable", "smoking")))
        uc_count = len(ANOMALY_CLASSES) - ua_count

        return ValidationResult(
            name="ì´ìƒ íƒì§€ í´ë˜ìŠ¤ ì •ì˜",
            passed=len(ANOMALY_CLASSES) >= 20,
            expected="UA/UC ìœ„í—˜ í´ë˜ìŠ¤ 20ê°œ ì´ìƒ ì •ì˜",
            actual=f"ì´ {len(ANOMALY_CLASSES)}ê°œ í´ë˜ìŠ¤ ì •ì˜",
            message="Monitoring Layerì—ì„œ ìœ„í—˜ ìƒí™© íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©"
        )
    except ImportError:
        return ValidationResult(
            name="ì´ìƒ íƒì§€ í´ë˜ìŠ¤ ì •ì˜",
            passed=False,
            expected="ANOMALY_CLASSES ì •ì˜",
            actual="monitoring ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨",
        )


def validate_pipeline_flow() -> ValidationResult:
    """íŒŒì´í”„ë¼ì¸ íë¦„ ê²€ì¦ (Monitoring â†’ Reasoning â†’ Action)"""
    try:
        from monitoring import detect_objects
        from reasoning import analyze_risk_with_vlm
        from action import generate_safety_guideline

        return ValidationResult(
            name="3-Layer íŒŒì´í”„ë¼ì¸ êµ¬ì¡°",
            passed=True,
            expected="Monitoring â†’ Reasoning â†’ Action í•¨ìˆ˜ ì¡´ì¬",
            actual="detect_objects, analyze_risk_with_vlm, generate_safety_guideline ë¡œë“œ ì„±ê³µ",
            message="íŒŒì´í”„ë¼ì¸ ì—°ë™ ì¤€ë¹„ ì™„ë£Œ"
        )
    except ImportError as e:
        return ValidationResult(
            name="3-Layer íŒŒì´í”„ë¼ì¸ êµ¬ì¡°",
            passed=False,
            expected="ëª¨ë“  Layer í•¨ìˆ˜ ì„í¬íŠ¸ ê°€ëŠ¥",
            actual=f"ì„í¬íŠ¸ ì‹¤íŒ¨: {e}",
        )


def validate_pydantic_schemas() -> ValidationResult:
    """Pydantic ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
    try:
        from schemas.monitoring_output import MonitoringOutput, DetectedObject
        from schemas.reasoning_output import ReasoningOutput

        # ìƒ˜í”Œ ë°ì´í„°ë¡œ ìŠ¤í‚¤ë§ˆ ê²€ì¦ (alias 'class' ì‚¬ìš©)
        sample_obj = DetectedObject(**{"class": "test", "confidence": 0.9, "box": [0, 0, 100, 100]})
        sample_monitoring = MonitoringOutput(
            status="anomaly_detected",
            image_path="/test/path.jpg",
            detected_objects=[sample_obj]
        )
        sample_reasoning = ReasoningOutput(
            image_path="/test/path.jpg",
            risk_level="HIGH",
            hazard_code="UA-01",
            reason="í…ŒìŠ¤íŠ¸ ì‚¬ìœ "
        )

        return ValidationResult(
            name="Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜",
            passed=True,
            expected="MonitoringOutput, ReasoningOutput ìŠ¤í‚¤ë§ˆ ì •ìƒ ë™ì‘",
            actual="ìŠ¤í‚¤ë§ˆ ìƒì„± ë° ê²€ì¦ ì„±ê³µ",
            message="Layer ê°„ ë°ì´í„° íƒ€ì… ì•ˆì „ì„± ë³´ì¥"
        )
    except Exception as e:
        return ValidationResult(
            name="Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜",
            passed=False,
            expected="ìŠ¤í‚¤ë§ˆ ìƒì„± ê°€ëŠ¥",
            actual=f"ì˜¤ë¥˜: {e}",
        )


def validate_inference_speed(image_path: str) -> ValidationResult:
    """ì¶”ë¡  ì†ë„ ê²€ì¦"""
    try:
        from monitoring import model

        start = time.time()
        results = model(image_path, verbose=False)
        elapsed = time.time() - start

        return ValidationResult(
            name="YOLO ì¶”ë¡  ì†ë„",
            passed=elapsed < 1.0,  # 1ì´ˆ ì´ë‚´
            expected="ì´ë¯¸ì§€ë‹¹ 1ì´ˆ ì´ë‚´",
            actual=f"{elapsed:.3f}ì´ˆ",
            message="ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥" if elapsed < 1.0 else "ìµœì í™” í•„ìš”"
        )
    except Exception as e:
        return ValidationResult(
            name="YOLO ì¶”ë¡  ì†ë„",
            passed=False,
            expected="ì¶”ë¡  ì‹¤í–‰ ê°€ëŠ¥",
            actual=f"ì˜¤ë¥˜: {e}",
        )


def run_full_validation(model_dir: str, test_image: Optional[str] = None) -> FrameworkValidation:
    """ì „ì²´ ì í•©ì„± ê²€ì¦ ì‹¤í–‰"""
    validation = FrameworkValidation()

    model_path = Path(model_dir)
    best_pt = model_path / "weights" / "best.pt"
    results_csv = model_path / "results.csv"

    # 1. ëª¨ë¸ íŒŒì¼ ê²€ì¦
    validation.add(validate_yolo_model(str(best_pt)))

    # 2. ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
    if results_csv.exists():
        validation.add(validate_yolo_performance(str(results_csv), min_map50=0.5))

    # 3. ì´ìƒ íƒì§€ í´ë˜ìŠ¤ ê²€ì¦
    validation.add(validate_anomaly_detection())

    # 4. íŒŒì´í”„ë¼ì¸ êµ¬ì¡° ê²€ì¦
    validation.add(validate_pipeline_flow())

    # 5. ìŠ¤í‚¤ë§ˆ ê²€ì¦
    validation.add(validate_pydantic_schemas())

    # 6. ì¶”ë¡  ì†ë„ ê²€ì¦ (í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆì„ ê²½ìš°)
    if test_image and Path(test_image).exists():
        validation.add(validate_inference_speed(test_image))

    return validation


if __name__ == "__main__":
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent))

    project_root = Path(__file__).parent.parent.parent
    models_dir = project_root / "models"

    # ê°€ì¥ ìµœê·¼ ëª¨ë¸ ì°¾ê¸°
    model_dirs = sorted(models_dir.glob("safety_*"), key=lambda x: x.stat().st_mtime, reverse=True)

    if not model_dirs:
        print("âŒ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        latest_model = model_dirs[0]
        print(f"ğŸ” ê²€ì¦ ëŒ€ìƒ ëª¨ë¸: {latest_model.name}")

        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì°¾ê¸°
        test_images = list((project_root / "data").rglob("**/val/images/*.jpg"))
        test_image = str(test_images[0]) if test_images else None

        validation = run_full_validation(str(latest_model), test_image)
        validation.print_summary()