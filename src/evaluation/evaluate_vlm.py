import os
import glob
import random
import argparse
import sys
import json
import time
import csv
import pandas as pd
from pathlib import Path
from tqdm import tqdm
from sklearn.metrics import accuracy_score, confusion_matrix
from dotenv import load_dotenv

# =========================================================
# [ì„¤ì •] í”„ë¡œì íŠ¸ ê²½ë¡œ ë° ëª¨ë“ˆ ì„í¬íŠ¸
# =========================================================
FILE_PATH = Path(__file__).resolve()
SRC_DIR = FILE_PATH.parent.parent
PROJECT_ROOT = SRC_DIR.parent

sys.path.append(str(SRC_DIR))
sys.path.append(str(PROJECT_ROOT))

try:
    from monitoring import detect_objects
    from reasoning import analyze_risk_with_vlm
    from schemas.monitoring_output import MonitoringOutput
except ImportError as e:
    print(f"ğŸš¨ ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    sys.exit(1)

load_dotenv()

# =========================================================
# [ì„¤ì •] ì •ë‹µì§€ ê¸°ì¤€
# =========================================================
RISK_CLASSES = [
    "UA-01", "UA-02", "UA-03", "UA-04", "UA-05", "UA-06", "UA-10",
    "UA-12", "UA-13", "UA-14", "UA-16", "UA-17", "UA-20",
    "UC-02", "UC-06", "UC-08", "UC-09", "UC-10", "UC-13", "UC-14",
    "UC-15", "UC-16", "UC-17", "UC-18", "UC-19", "UC-20", "UC-21", "UC-22",
    "SO-21", "SO-22"
]

def load_mapping(mapping_csv_path):
    """filename_mapping.csvë¥¼ ì½ì–´ì„œ {ìƒˆíŒŒì¼ëª…: ì›ë³¸ê²½ë¡œ} ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
    mapping = {}
    if not os.path.exists(mapping_csv_path):
        print(f"âš ï¸ ë§¤í•‘ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mapping_csv_path}")
        return mapping
        
    try:
        with open(mapping_csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                mapping[row['New_Filename']] = row['Original_Path']
        print(f"âœ… ë§¤í•‘ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(mapping)}ê°œ íŒŒì¼ ì •ë³´")
    except Exception as e:
        print(f"ğŸš¨ ë§¤í•‘ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        
    return mapping

def get_ground_truth_from_json(image_name, mapping_data):
    """
    ë§¤í•‘ ì •ë³´ë¥¼ ì´ìš©í•´ ì›ë³¸ JSONì„ ì°¾ì•„ ì§„ì§œ ì •ë‹µ(Ground Truth)ì„ ë°˜í™˜
    """
    original_img_path = mapping_data.get(image_name)
    if not original_img_path:
        return []

    # 1. ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ -> ì›ë³¸ JSON ê²½ë¡œ ë³€í™˜
    # ê·œì¹™: /original/ -> /label/
    # ê·œì¹™: TS_ -> TL_, VS_ -> VL_ (í´ë”ëª… ì ‘ë‘ì‚¬ ë³€ê²½)
    # ê·œì¹™: .jpg/.png -> .json
    
    json_path = original_img_path.replace("/original/", "/label/")
    json_path = json_path.replace("TS_", "TL_").replace("VS_", "VL_")
    json_path = os.path.splitext(json_path)[0] + ".json"
    
    if not os.path.exists(json_path):
        return []

    detected_risks = set()
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
            # (A) Situation ID í™•ì¸ (ê°€ì¥ ì¤‘ìš”í•œ ì •ë‹µ)
            raw_info = data.get("Raw data Info.", {})
            sit_id = raw_info.get("situation_ID")
            if sit_id in RISK_CLASSES:
                detected_risks.add(sit_id)
                
            # (B) Annotation í™•ì¸ (ë³´ì¡° ì •ë‹µ)
            annotations = data.get("Learning data info.", {}).get("annotation", [])
            for ann in annotations:
                cls_id = ann.get("class_id")
                if cls_id in RISK_CLASSES:
                    detected_risks.add(cls_id)
                    
    except Exception as e:
        print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜ ({json_path}): {e}")
        return []

    return list(detected_risks)


class VLMEvaluator:
    def __init__(self, data_root: str, mapping_path: str, sample_size: int = 50):
        self.data_root = Path(data_root)
        self.sample_size = sample_size
        self.val_images_dir = self.data_root / "val" / "images"
        
        # [ìˆ˜ì •] ì—¬ê¸°ì„œ ë§¤í•‘ ë°ì´í„°ë¥¼ ë¡œë“œí•´ì„œ self.mapping_dataì— ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤!
        self.mapping_data = load_mapping(mapping_path)

    def run(self, output_csv="vlm_evaluation_result.csv", mode="hybrid"):
        if not self.val_images_dir.exists():
            print(f"ğŸš¨ ì˜¤ë¥˜: ê²€ì¦ ë°ì´í„° ê²½ë¡œ ì—†ìŒ ({self.val_images_dir})")
            return

        image_files = sorted(list(self.val_images_dir.glob("*.jpg")) + list(self.val_images_dir.glob("*.png")))
        print(f"ğŸ“‚ ì „ì²´ ê²€ì¦ ì´ë¯¸ì§€: {len(image_files)}ì¥")

        if self.sample_size and len(image_files) > self.sample_size:
            print(f"ğŸ² {self.sample_size}ì¥ ëœë¤ ìƒ˜í”Œë§...")
            random.seed(42)
            image_files = random.sample(image_files, self.sample_size)
        
        results = []
        y_true_binary = []
        y_pred_binary = []
        y_true_code = []
        y_pred_code = []
        
        total_yolo_time = 0.0
        total_vlm_time = 0.0
        total_proc_time = 0.0
        vlm_call_count = 0

        print(f"ğŸš€ í‰ê°€ ì‹œì‘ (Mode: {mode.upper()})...")
        
        for img_path in tqdm(image_files):
            t_start = time.time()
            t_yolo = 0.0
            t_vlm = 0.0
            
            # 1. ì •ë‹µ(GT) í™•ì¸ - ì›ë³¸ JSON ê¸°ë°˜
            gt_codes = get_ground_truth_from_json(img_path.name, self.mapping_data)
            gt_binary = "ANOMALY" if gt_codes else "NORMAL"
            gt_codes_str = ", ".join(gt_codes) if gt_codes else "NONE"
            
            # 2. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            detection_result = None
            reasoning_result = None
            
            # (A) YOLO
            if mode in ["hybrid", "vlm-evaluate"]:
                t0 = time.time()
                detection_result = detect_objects(str(img_path))
                t_yolo = time.time() - t0
            else:
                detection_result = MonitoringOutput(status="normal", image_path=str(img_path), detected_objects=[])
                t_yolo = 0.0

            # (B) VLM
            should_run_vlm = False
            if mode in ["vlm-evaluate", "vlm-only"]:
                should_run_vlm = True
            elif mode == "hybrid" and detection_result.status == "anomaly_detected":
                should_run_vlm = True
            
            if should_run_vlm:
                t2 = time.time()
                reasoning_result = analyze_risk_with_vlm(detection_result)
                t_vlm = time.time() - t2
                vlm_call_count += 1
            
            t_total = time.time() - t_start
            total_yolo_time += t_yolo
            total_vlm_time += t_vlm
            total_proc_time += t_total

            # 3. ì˜ˆì¸¡ ê²°ê³¼ íŒŒì‹±
            pred_code = "NONE"
            pred_binary = "NORMAL"
            reason = "Skipped"
            
            if reasoning_result:
                pred_code = reasoning_result.hazard_code if reasoning_result.hazard_code else "NONE"
                reason = reasoning_result.reason
                
                clean_code = str(pred_code).upper().strip()
                SAFE_KEYWORDS = ["NONE", "SAFE", "N/A", "NULL", "NONE"]
                
                if clean_code not in SAFE_KEYWORDS:
                     pred_binary = "ANOMALY"
                else:
                     pred_binary = "NORMAL"
            elif mode == "hybrid" and not should_run_vlm:
                pred_binary = "NORMAL"
                pred_code = "NONE"
                reason = "Skipped by YOLO"

            # 4. ì±„ì 
            is_binary_correct = (gt_binary == pred_binary)
            
            # ë³µìˆ˜ ì •ë‹µ ì¸ì • ë¡œì§
            if pred_code in gt_codes:
                is_code_correct = True
            elif pred_code == "NONE" and not gt_codes:
                is_code_correct = True
            else:
                is_code_correct = False

            results.append({
                "Image": img_path.name,
                "GT_Codes": gt_codes_str,
                "Pred_Code": pred_code,
                "GT_Binary": gt_binary,
                "Pred_Binary": pred_binary,
                "Acc_Binary": is_binary_correct,
                "Acc_Code": is_code_correct,
                "Reason": reason,
                "Time_Total": t_total
            })
            
            y_true_binary.append(gt_binary)
            y_pred_binary.append(pred_binary)
            
            if gt_binary == "ANOMALY":
                # ì •í™•ë„ í†µê³„ìš©: ë§ì·„ìœ¼ë©´ ì •ë‹µ ì½”ë“œ ì‚¬ìš©, í‹€ë ¸ìœ¼ë©´ ì²« ë²ˆì§¸ GT ì‚¬ìš©
                target_gt = pred_code if is_code_correct else gt_codes[0]
                y_true_code.append(target_gt)
                y_pred_code.append(pred_code)

        # 5. ê²°ê³¼ ì €ì¥
        if not results:
            return

        df = pd.DataFrame(results)
        Path(output_csv).parent.mkdir(parents=True, exist_ok=True)
        df.to_csv(output_csv, index=False, encoding='utf-8-sig')
        
        print(f"\nğŸ“Š [í‰ê°€ ê²°ê³¼ - Mode: {mode.upper()}] (N={len(results)})")
        print(f"1. ğŸ›¡ï¸ ìœ„í—˜ ê°ì§€ ì •í™•ë„ (Binary): {df['Acc_Binary'].mean():.2%}")
        print(f"2. ğŸ¯ ìœ„í—˜ ì‹ë³„ ì •í™•ë„ (Code):   {df['Acc_Code'].mean():.2%}")
        
        if y_true_code:
            risk_code_acc = accuracy_score(y_true_code, y_pred_code)
            print(f"   - (ìœ„í—˜ ë°ì´í„° ëŒ€ìƒ) ì‹ë³„ ì •í™•ë„: {risk_code_acc:.2%}")

        avg_yolo = total_yolo_time / len(results)
        avg_vlm = total_vlm_time / len(results)
        avg_total = total_proc_time / len(results)
        vlm_rate = vlm_call_count / len(results)
        
        print(f"\nâ±ï¸ [íš¨ìœ¨ì„± ë¶„ì„]")
        print(f"   - í‰ê·  YOLO ì‹œê°„: {avg_yolo:.4f} sec")
        print(f"   - í‰ê·  VLM  ì‹œê°„: {avg_vlm:.4f} sec")
        print(f"   - í‰ê·  ì „ì²´ ì‹œê°„: {avg_total:.4f} sec")
        print(f"   - VLM í˜¸ì¶œ ë¹„ìœ¨:  {vlm_rate:.2%} ({vlm_call_count}/{len(results)})")

        print("\nğŸ“‘ [í˜¼ë™ í–‰ë ¬]")
        print(confusion_matrix(y_true_binary, y_pred_binary, labels=["ANOMALY", "NORMAL"]))


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data-root', type=str, required=True)
    parser.add_argument('--mapping-csv', type=str, required=True, help='ë§¤í•‘ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--sample', type=int, default=50)
    parser.add_argument('--output', type=str, default='logs/eval_result.csv')
    parser.add_argument('--mode', type=str, default='hybrid')
    args = parser.parse_args()
    
    if not os.environ.get("OPENAI_API_KEY"):
        print("ğŸš¨ API Key í•„ìš”")
        return
        
    # [ìˆ˜ì •] mapping_csv ì¸ì ì „ë‹¬
    evaluator = VLMEvaluator(args.data_root, args.mapping_csv, args.sample)
    evaluator.run(args.output, args.mode)

if __name__ == "__main__":
    main()