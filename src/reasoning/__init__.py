# src/reasoning/__init__.py

import os
import base64
import json
from openai import OpenAI
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì™€ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
# ì´ ì½”ë“œëŠ” ëª¨ë“ˆì´ ì„í¬íŠ¸ë  ë•Œ í•œ ë²ˆ ì‹¤í–‰ë©ë‹ˆë‹¤.
api_key_from_env = os.environ.get("OPENAI_API_KEY")
if api_key_from_env:
    client = OpenAI(api_key=api_key_from_env)
else:
    print("ğŸš¨ [Reasoning] ì˜¤ë¥˜: OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    client = None # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨

def encode_image_to_base64(image_path):
    """ì´ë¯¸ì§€ë¥¼ Base64 ë¬¸ìì—´ë¡œ ì¸ì½”ë”©í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except FileNotFoundError:
        print(f"ğŸš¨ [Reasoning] ì˜¤ë¥˜: ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {image_path}")
        return None

def analyze_risk_with_vlm(detection_result):
    """
    [ì‹¤ì œ Reasoning Layer í•¨ìˆ˜]
    GPT-4o VLM APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ì˜ ìœ„í—˜ ìˆ˜ì¤€ê³¼ ì´ìœ ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    if not client:
        print("ğŸš« [Reasoning] OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ API í˜¸ì¶œì„ ê±´ë„ˆ<0xEB><0><0xA4>ë‹ˆë‹¤.")
        return None # í´ë¼ì´ì–¸íŠ¸ ì—†ìœ¼ë©´ ì‹¤í–‰ ë¶ˆê°€

    print("ğŸ§  [Reasoning] GPT-4o VLMìœ¼ë¡œ ìœ„í—˜ ìƒí™©ì„ ì‹¬ì¸µ ë¶„ì„ ì¤‘...")

    image_path = detection_result.get("image_path")
    if not image_path:
        print("ğŸš¨ [Reasoning] ì˜¤ë¥˜: detection_resultì— 'image_path'ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # VLMì— ì „ì†¡í•  ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤.
    base64_image = encode_image_to_base64(image_path)
    if not base64_image:
        return None # ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨

    # VLMì—ê²Œ ë‚´ë¦´ ì§€ì‹œì‚¬í•­ (í”„ë¡¬í”„íŠ¸)ì„ ì‘ì„±í•©ë‹ˆë‹¤.
    prompt_text = """
    ë‹¹ì‹ ì€ ì œì¡° ê³µì¥ì˜ AI ì•ˆì „ ê´€ë¦¬ìì…ë‹ˆë‹¤.
    ì²¨ë¶€ëœ ì´ë¯¸ì§€ëŠ” ê³µì¥ CCTV í™”ë©´ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ë©´ë°€íˆ ë¶„ì„í•˜ì—¬ ì ì¬ì ì¸ ì•ˆì „ ìœ„í—˜ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

    - ìœ„í—˜ ìˆ˜ì¤€(risk_level)ì€ "LOW"(ì•ˆì „), "MED"(ì£¼ì˜), "HIGH"(ë†’ì€ ìœ„í—˜) ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.
    - ìœ„í—˜ì„ íŒë‹¨í•œ êµ¬ì²´ì ì¸ ì´ìœ (reason)ë¥¼ í•œêµ­ì–´ë¡œ í•œ ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

    ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤:
    {"risk_level": "...", "reason": "..."}
    """

    try:
        # OpenAI APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
        response = client.chat.completions.create(
            model="gpt-4o", # ë˜ëŠ” "gpt-4o-mini" ë“± ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt_text},
                        {
                            "type": "image_url",
                            # ì´ë¯¸ì§€ íƒ€ì…ì— ë§ê²Œ jpeg ë˜ëŠ” png ì§€ì •
                            "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                        }
                    ]
                }
            ],
            max_tokens=300,
            response_format={"type": "json_object"} # ì‘ë‹µì„ JSON í˜•ì‹ìœ¼ë¡œ ê°•ì œ
        )

        # API ì‘ë‹µì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        analysis_result_str = response.choices[0].message.content
        analysis_result = json.loads(analysis_result_str)

        print(f"âœ… [Reasoning] VLM ë¶„ì„ ì™„ë£Œ: {analysis_result}")
        return analysis_result

    except Exception as e:
        print(f"ğŸš¨ [Reasoning] VLM API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None