# src/action.py

import os
import json
from openai import OpenAI
from dotenv import load_dotenv
from typing import Optional # <--  Optional ì„í¬íŠ¸

# ---  Pydantic ìŠ¤í‚¤ë§ˆ ì„í¬íŠ¸ ---
from schemas.reasoning_output import ReasoningOutput # ì…ë ¥ íƒ€ì…
from schemas.action_output import ActionOutput, MultilingualGuidelines # ë°˜í™˜ íƒ€ì…

# .env íŒŒì¼ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
load_dotenv()
api_key_from_env = os.environ.get("OPENAI_API_KEY")
if api_key_from_env:
    client = OpenAI(api_key=api_key_from_env)
else:
    print("ğŸš¨ [Action] ì˜¤ë¥˜: OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    client = None

# ---  í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ì— Pydantic íƒ€ì… íŒíŠ¸ ì ìš© ---
def generate_safety_guideline(analysis_result: ReasoningOutput) -> ActionOutput:
    """
    [ì‹¤ì œ Action Layer í•¨ìˆ˜]
    VLM ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ„í—˜ ë“±ê¸‰ì— ë”°ë¼ ì¡°ì¹˜ë¥¼ ì·¨í•˜ê³ ,
    HIGH ìœ„í—˜ ì‹œ LLMì„ í˜¸ì¶œí•˜ì—¬ ë‹¤êµ­ì–´ ì•ˆì „ ì§€ì¹¨ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not client:
        print("ğŸš« [Action] OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ LLM í˜¸ì¶œì„ ê±´ë„ˆ<0xEB><0><0xA4>ë‹ˆë‹¤.")
        # ---  Pydantic ëª¨ë¸ë¡œ ë°˜í™˜ ---
        return ActionOutput(
            status="error_client_not_initialized",
            risk_level_processed=analysis_result.risk_level,
            hazard_code_processed=analysis_result.hazard_code,
            reason_detected=analysis_result.reason
        )

    # ---  Pydantic ê°ì²´ ì†ì„±ìœ¼ë¡œ ì ‘ê·¼ ---
    risk_level = analysis_result.risk_level
    reason = analysis_result.reason
    hazard_code = analysis_result.hazard_code

    print(f"ğŸ“¢ [Action] ìœ„í—˜ ë“±ê¸‰ '{risk_level}'(ì½”ë“œ: {hazard_code})ì— ë”°ë¥¸ ì¡°ì¹˜ ì‹¤í–‰...")

    # ---  ëª¨ë“  ë°˜í™˜ê°’ì„ ActionOutput Pydantic ëª¨ë¸ë¡œ ê°ì‹¸ê¸° ---
    if risk_level == "LOW":
        print("â¡ï¸ [Action] ìœ„í—˜ ë“±ê¸‰ LOW: ë¡œê·¸ ê¸°ë¡ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        # ì—¬ê¸°ì— ë¡œê·¸ ê¸°ë¡ ë¡œì§ ì¶”ê°€ (ì˜ˆ: íŒŒì¼ ì €ì¥, DB ì €ì¥ ë“±)
        return ActionOutput(
            status="logged",
            risk_level_processed=risk_level,
            hazard_code_processed=hazard_code,
            reason_detected=reason
        )

    elif risk_level == "MED":
        print("âš ï¸ [Action] ìœ„í—˜ ë“±ê¸‰ MED: í™•ì¸ ì•Œë¦¼ í‘œì‹œ.")
        print(f"   - í™•ì¸ í•„ìš”: {reason} (ìœ„í—˜ ì½”ë“œ: {hazard_code})")
        # ì—¬ê¸°ì— í™•ì¸ ì•Œë¦¼ UI í‘œì‹œ ë˜ëŠ” ë©”ì‹œì§€ ì „ì†¡ ë¡œì§ ì¶”ê°€
        return ActionOutput(
            status="confirmation_requested",
            risk_level_processed=risk_level,
            hazard_code_processed=hazard_code,
            reason_detected=reason
        )

    elif risk_level == "HIGH":
        print("ğŸš¨ [Action] ìœ„í—˜ ë“±ê¸‰ HIGH: LLM í˜¸ì¶œí•˜ì—¬ ë‹¤êµ­ì–´ ì•ˆì „ ì§€ì¹¨ ìƒì„±...")

        # --- (ìˆ˜ì • 2) LLM í”„ë¡¬í”„íŠ¸ì— hazard_codeì™€ reasonì„ ë™ì ìœ¼ë¡œ ì‚½ì… ---
        prompt_for_llm = f"""
        ë‹¤ìŒì€ ìŠ¤ë§ˆíŠ¸ ê³µì¥ì—ì„œ ê°ì§€ëœ ì‹¬ê°í•œ ì•ˆì „ ìœ„í—˜ ìƒí™©ì…ë‹ˆë‹¤:

        [í™•ì¸ëœ ìœ„í—˜ ì •ë³´]
        * ìœ„í—˜ ì½”ë“œ: {hazard_code}
        * ìƒí™© ì„¤ëª…: {reason}

        ì´ ìƒí™©ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í–‰ë™ ì§€ì¹¨ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        ì§€ì¹¨ì€ ë‹¤ìŒ ì–¸ì–´ë¡œ ê°ê° ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤: í•œêµ­ì–´, ì˜ì–´, ë² íŠ¸ë‚¨ì–´.

        ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        {{
          "guideline_ko": "...",
          "guideline_en": "...",
          "guideline_vi": "..."
        }}
        """

        try:
            # LLM API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4o", 
                messages=[
                    {"role": "user", "content": prompt_for_llm}
                ],
                max_tokens=500,
                response_format={"type": "json_object"}
            )

            guideline_str = response.choices[0].message.content
            guidelines_dict = json.loads(guideline_str)
            
            # ---  LLM ê²°ê³¼ë¥¼ Pydantic ëª¨ë¸(MultilingualGuidelines)ë¡œ ë³€í™˜ ---
            output_guidelines = MultilingualGuidelines(**guidelines_dict)
            output_status = "multilingual_guideline_generated"

            print("--- [ìƒì„±ëœ ë‹¤êµ­ì–´ ì•ˆì „ ì§€ì¹¨] ---")
            print(f"ğŸ‡°ğŸ‡· (í•œêµ­ì–´): {output_guidelines.guideline_ko}")
            print(f"ğŸ‡ºğŸ‡¸ (English): {output_guidelines.guideline_en}")
            print(f"ğŸ‡»ğŸ‡³ (Tiáº¿ng Viá»‡t): {output_guidelines.guideline_vi}")
            print("---------------------------------")
            
            # ---  ìµœì¢… ê²°ê³¼ë¥¼ ActionOutput ëª¨ë¸ë¡œ ë°˜í™˜ ---
            return ActionOutput(
                status=output_status,
                risk_level_processed=risk_level,
                hazard_code_processed=hazard_code,
                reason_detected=reason,
                guidelines=output_guidelines
            )

        except Exception as e:
            print(f"ğŸš¨ [Action] LLM API í˜¸ì¶œ ë˜ëŠ” Pydantic ë³€í™˜ ì˜¤ë¥˜: {e}")
            return ActionOutput(
                status=f"error_llm_api_call",
                risk_level_processed=risk_level,
                hazard_code_processed=hazard_code,
                reason_detected=reason
            )

    else:
        print(f"â“ [Action] ì•Œ ìˆ˜ ì—†ëŠ” ìœ„í—˜ ë“±ê¸‰: {risk_level}")
        return ActionOutput(
            status="unknown_risk_level",
            risk_level_processed=risk_level,
            hazard_code_processed=hazard_code,
            reason_detected=reason
        )